<p align="center">
  <img src="assets/minillm-icon.svg" alt="MiniLLM logo" width="96" height="96"/>
</p>
<h1 align="center">MiniLLM</h1>
<p align="center">è½»é‡çº§ LLM è®­ç»ƒã€å¯¹é½ã€éƒ¨ç½²ä¸€ä½“åŒ–é¡¹ç›®ï¼Œé¢å‘ä» 0 åˆ° 1 çš„å­¦ä¹ ä¸å¤ç°ã€‚</p>
<p align="center">
  <a href="./README_en.md">English</a> Â·
  <a href="./docs/README.md">Docs</a> Â·
  <a href="./docs/booklet_cn.md">Booklet</a>
</p>
<p align="center">
  <img alt="license" src="https://img.shields.io/badge/license-MIT-blue.svg"/>
  <img alt="python" src="https://img.shields.io/badge/python-3.10%2B-3776AB.svg"/>
  <img alt="platform" src="https://img.shields.io/badge/platform-linux%20%7C%20macos-lightgrey.svg"/>
</p>

> æœ¬ä»“åº“ç”± [MiniMind](https://github.com/jingyaogong/minimind) é¡¹ç›®é‡æ„è€Œæ¥ï¼Œä¿ç•™â€œä»é›¶å®ç°è½»é‡çº§ LLMâ€çš„æ•™å­¦ç›®æ ‡ï¼Œå¹¶è¡¥å…¨æ•°æ®ã€è®­ç»ƒã€è¯„ä¼°ä¸éƒ¨ç½²æµç¨‹ã€‚

---

## âœ¨ ç‰¹æ€§

- ç«¯åˆ°ç«¯è®­ç»ƒé“¾è·¯ï¼šé¢„è®­ç»ƒ â†’ SFT â†’ åå¥½å¯¹é½ï¼ˆDPO/GRPO/PPO/SPOï¼‰â†’ è’¸é¦
- è®­ç»ƒä¸æ¨ç†ï¼šåŸç”Ÿ PyTorch + DeepSpeed + MLXï¼ˆApple Siliconï¼‰
- æ•°æ®ç®¡çº¿ï¼šæ¸…æ´—ã€å»é‡ã€è´¨é‡è¯„ä¼°ã€RustBPE åˆ†è¯
- éƒ¨ç½²æ–¹å¼ï¼šStreamlit WebUIã€OpenAI åè®® APIã€llama.cpp/vLLM/Ollama å¯¼å‡º
- è¯„ä¼°å·¥å…·ï¼šC-Evalã€CMMLUã€OpenBookQA ç­‰åŸºå‡†è¯„æµ‹

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1) ç¯å¢ƒå‡†å¤‡

```bash
conda create -n minillm python=3.10 -y
conda activate minillm
pip install -r requirements.txt
```

å¦‚æœä¸‹è½½è¾ƒæ…¢ï¼Œå¯ä½¿ç”¨æ¸…åæºï¼š

```bash
python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt
```

### 2) æ•°æ®å‡†å¤‡

- å°†åŸå§‹è¯­æ–™æ”¾åœ¨ `dataset/` æˆ–è‡ªå®šä¹‰ç›®å½•
- è¿è¡Œ `scripts/prepare_data.sh` å®Œæˆå»é‡ã€åˆ†è¯ã€è¿‡æ»¤
- å¤„ç†åçš„æ•°æ®ä¼šåŒæ­¥åˆ° `data/` ä¾›è®­ç»ƒè„šæœ¬ä½¿ç”¨

### 3) ä¸€é”®è®­ç»ƒ

```bash
# é¢„è®­ç»ƒ â†’ SFT â†’ DPO
scripts/run.sh

# è·³è¿‡é¢„è®­ç»ƒï¼Œä»…æ‰§è¡Œ SFT + DPO
scripts/run.sh --skip-pretrain

# çƒŸé›¾æµ‹è¯•ï¼ˆCPU + å°æ•°æ®ï¼‰
scripts/run.sh --smoke-test
```

### 4) WebUI

```bash
python -m streamlit run scripts/web_demo.py
```

è®­ç»ƒæ—¥å¿—ã€æƒé‡ä¸è¯„ä¼°è¾“å‡ºé»˜è®¤ä¿å­˜åœ¨ `out/`ã€‚

---

## ğŸ MLXï¼ˆApple Siliconï¼‰

```bash
# è‡ªåŠ¨è·‘é€šä¸‹è½½æ•°æ® â†’ é¢„è®­ç»ƒ â†’ SFT
bash scripts/run_mlx.sh

# Smoke Test
bash scripts/run_mlx.sh --smoke-test
```

MLX äº§ç‰©é»˜è®¤å†™å…¥ `out/mlx`ï¼ŒWebUI ä¼šè‡ªåŠ¨è§£ææœ€æ–° `step_` checkpointã€‚

---

## ğŸ§ª è’¸é¦ï¼ˆå¯é€‰ï¼‰

### MLX ä¸€é”®è’¸é¦ï¼ˆOllama æ•™å¸ˆæ¨¡å‹ï¼‰

```bash
# éœ€è¦å…ˆå¯åŠ¨ ollama serveï¼Œå¹¶æ‹‰å–æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚ qwen3:0.6bï¼‰
bash scripts/run_mlx_distill_ollama.sh
```

å¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´ï¼š

```bash
OLLAMA_MODEL=qwen3:0.6b DATA_JSONL=out/distill_ollama_qwen3_0.6b/synth.jsonl OUT_DIR=out/mlx_distill/qwen3_0.6b_sft \
  bash scripts/run_mlx_distill_ollama.sh
```

### EAGLE-3 speculatorï¼ˆQwen3-0.6B / MiniLLMï¼Œçº¯åˆæˆæ•°æ®ï¼‰

> - speculator é»˜è®¤ä¼šæ ¹æ®ç›®æ ‡æ¨¡å‹å¤§å°è‡ªåŠ¨è®¾ç½®ï¼›å¯ç”¨ `--spec_len`/`--spec_layers` æ˜¾å¼è¦†ç›–ã€‚
> - `--head_rank` é»˜è®¤è‡ªåŠ¨è®¾ç½®ï¼ˆhidden_size/8ï¼ŒèŒƒå›´ 32-256ï¼‰ï¼›å¯æ˜¾å¼æŒ‡å®šæˆ–è®¾ä¸º 0 å…³é—­ä½ç§©å¤´ã€‚
> - MLX è®­ç»ƒè‹¥ `out_dir` ä¸‹å­˜åœ¨ checkpoint ä¼šè‡ªåŠ¨ç»§ç»­ï¼›å¦‚éœ€é‡æ–°å¼€å§‹è¯·åŠ  `--no_resume`ã€‚

#### Qwen3-0.6Bï¼ˆTorchï¼‰

```bash
# Torchï¼šè‡ªåŠ¨ç”Ÿæˆåˆæˆæ•°æ® + è®­ç»ƒ EAGLE-3 style speculator
python speculator/train/torch/train_eagle3_speculator.py
# Torchï¼šåŸºå‡†å¯¹æ¯”ï¼ˆbaseline vs speculatorï¼‰
python speculator/infer/torch/bench.py --max_samples 16
```

#### Qwen3-0.6Bï¼ˆMLXï¼‰

```bash
# MLXï¼šè‡ªåŠ¨ç”Ÿæˆåˆæˆæ•°æ® + è®­ç»ƒ speculator
python speculator/train/mlx/train_eagle3_speculator.py --hf_repo Qwen/Qwen3-0.6B
# MLXï¼šåŸºå‡†å¯¹æ¯”ï¼ˆbaseline vs speculatorï¼‰
python speculator/infer/mlx/bench.py --hf_repo Qwen/Qwen3-0.6B --max_samples 16
```

#### Qwen3-1.7B + AngelSlim EAGLE-3 æƒé‡ï¼ˆMLXï¼Œå…è®­ç»ƒï¼‰

```bash
# 1) å¯é€‰ï¼šå…ˆæŠŠ Qwen3-1.7B è½¬æˆ MLX æƒé‡ï¼ˆé¿å…é¦–æ¬¡åŠ è½½ä» HF è½¬æ¢ï¼‰
python -m mlx_train.cli.hf_convert --hf_repo Qwen/Qwen3-1.7B --out_dir out/mlx_hf/qwen_qwen3_1_7b

# 2) ä¸‹è½½ AngelSlim EAGLE-3 drafter æƒé‡
python - <<'PY'
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id="AngelSlim/Qwen3-1.7B_eagle3",
    local_dir="out/eagle3_speculator_hf/angelslim_qwen3_1_7b_eagle3",
)
PY

# 3) MLXï¼šåŸºå‡†å¯¹æ¯”ï¼ˆbaseline vs EAGLE-3 weightsï¼‰
python speculator/infer/mlx/bench.py \
  --hf_repo Qwen/Qwen3-1.7B \
  --model_dir out/mlx_hf/qwen_qwen3_1_7b \
  --eagle3_dir out/eagle3_speculator_hf/angelslim_qwen3_1_7b_eagle3 \
  --max_samples 16
```

#### Qwen3-1.7B + AngelSlim EAGLE-3 æƒé‡ï¼ˆTorchï¼Œå…è®­ç»ƒï¼‰

```bash
# 1) ä¸‹è½½ AngelSlim EAGLE-3 drafter æƒé‡
python - <<'PY'
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id="AngelSlim/Qwen3-1.7B_eagle3",
    local_dir="out/eagle3_speculator_hf/angelslim_qwen3_1_7b_eagle3",
)
PY

# 2) Torchï¼šåŸºå‡†å¯¹æ¯”ï¼ˆbaseline vs EAGLE-3 weightsï¼‰
# æ³¨æ„ï¼šAngelSlim EAGLE-3 éœ€ä½¿ç”¨ --eagle3_dirï¼ˆæ ‘è§£ç è·¯å¾„ï¼‰ï¼Œ--speculator_dir ä»…ç”¨äºæœ¬é¡¹ç›®è®­ç»ƒçš„ speculatorã€‚
python speculator/infer/torch/bench.py \
  --target_arch qwen3 \
  --target_model Qwen/Qwen3-1.7B \
  --eagle3_dir out/eagle3_speculator_hf/angelslim_qwen3_1_7b_eagle3 \
  --max_samples 16
```

#### MiniLLMï¼ˆTorchï¼‰

```bash
# Torchï¼šè®­ç»ƒï¼ˆæŒ‡å®š MiniLLM checkpoint + tokenizerï¼‰
python speculator/train/torch/train_eagle3_speculator.py \
  --target_arch minillm \
  --minillm_ckpt out/pretrain_512.pth \
  --minillm_tokenizer ./model
# Torchï¼šåŸºå‡†å¯¹æ¯”
python speculator/infer/torch/bench.py \
  --target_arch minillm \
  --minillm_ckpt out/pretrain_512.pth \
  --minillm_tokenizer ./model
```

#### MiniLLMï¼ˆMLXï¼‰

```bash
# MLXï¼šè®­ç»ƒï¼ˆä½¿ç”¨ mlx_train äº§å‡ºçš„ checkpoint ç›®å½•ï¼‰
python speculator/train/mlx/train_eagle3_speculator.py \
  --target_arch minillm \
  --minillm_ckpt_dir out/mlx/sft/checkpoints/step_00000050 \
  --minillm_tokenizer ./model
# MLXï¼šåŸºå‡†å¯¹æ¯”
python speculator/infer/mlx/bench.py \
  --target_arch minillm \
  --minillm_ckpt_dir out/mlx/sft/checkpoints/step_00000050 \
  --minillm_tokenizer ./model
```

> MLX æ¨ç†/è®­ç»ƒä¾èµ– `mlx-lm`ï¼ˆå½“å‰ä¸ transformers==5.0.0rc1 ç»‘å®šï¼‰ï¼Œå»ºè®®ä½¿ç”¨ç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒã€‚

### PyTorch è’¸é¦è®­ç»ƒ

```bash
# é»˜è®¤è¯»å– out/ ä¸­çš„ full_sft_512.pthï¼ˆå­¦ç”Ÿï¼‰ä¸ full_sft_768.pthï¼ˆæ•™å¸ˆï¼‰
python trainer/train_distillation.py --data_path dataset/sft_xxx.jsonl --out_dir out
```

---

## ğŸ§ª æ¨ç†ä¸éƒ¨ç½²

- **OpenAI å…¼å®¹ API**ï¼š`python scripts/serve_openai_api.py`ï¼ˆé»˜è®¤ç«¯å£ 8998ï¼‰
- **è¯„æµ‹/æ¨ç†è„šæœ¬**ï¼š`python eval_model.py --model_mode 1`
- **è®­ç»ƒç›‘æ§é¢æ¿**ï¼š`python -m scripts.dashboard.app --host 0.0.0.0 --port 8008`

---

## ğŸ§­ ä»“åº“ç»“æ„

```text
.
â”œâ”€â”€ apps/                # æœåŠ¡ä¸ UIï¼ˆOpenAI API / WebUI / Dashboardï¼‰
â”œâ”€â”€ data/                # æ•°æ®ç¼“å­˜ç›®å½•
â”œâ”€â”€ dataset/             # å…¬å¼€æ•°æ®é›†ç¤ºä¾‹ä¸è„šæœ¬
â”œâ”€â”€ docs/                # æ–‡æ¡£ä¸æŒ‡å—
â”œâ”€â”€ speculator/          # Speculator è®­ç»ƒ/æ¨ç†å…¥å£ï¼ˆtorch/mlxï¼‰
â”œâ”€â”€ mlx_train/           # MLX è®­ç»ƒä¸æ¨ç†
â”œâ”€â”€ model/               # MiniLLM Dense/MoE å®ç°
â”œâ”€â”€ pipelines/           # ä¸€é”®è®­ç»ƒ/æ¨ç†æµæ°´çº¿è„šæœ¬ï¼ˆä¸»é€»è¾‘ï¼‰
â”œâ”€â”€ scripts/             # è„šæœ¬ä¸å·¥å…·
â”œâ”€â”€ tokenizer/           # RustBPE åˆ†è¯ä¸è¯è¡¨
â”œâ”€â”€ trainer/             # è®­ç»ƒ/å¯¹é½/è’¸é¦è„šæœ¬
â”œâ”€â”€ tools/               # æ•°æ®/è¯„æµ‹/è½¬æ¢/åˆ†è¯ç­‰å·¥å…·è„šæœ¬
â””â”€â”€ utils/               # å…¬å…±å·¥å…·ä¸è¯„ä¼°è„šæœ¬
```

---

## ğŸ“š èµ„æºä¸æ–‡æ¡£

- [docs/README.md](./docs/README.md)ï¼šæ–‡æ¡£å…¥å£ä¸å¯¼èˆª
- [docs/booklet_cn.md](./docs/booklet_cn.md)ï¼šå®Œæ•´ä¸­æ–‡å°å†Œå­
- [docs/changelog/CHANGELOG.md](./docs/changelog/CHANGELOG.md)ï¼šç‰ˆæœ¬è®°å½•
- [ModelScope: MiniMind-Reasoning](https://www.modelscope.cn/studios/gongjy/minimind-reasoning)
- [ModelScope: MiniMind](https://www.modelscope.cn/studios/gongjy/minimind)
- [Bilibili è§†é¢‘ä»‹ç»](https://www.bilibili.com/video/BV12dHPeqE72)

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿é€šè¿‡ Issue æˆ– Pull Request åé¦ˆé—®é¢˜å’Œæ”¹è¿›å»ºè®®ã€‚è¯·å…ˆé˜…è¯» [docs/CODE_OF_CONDUCT.md](./docs/CODE_OF_CONDUCT.md)ï¼Œå¹¶å‚è€ƒ [AGENTS.md](./AGENTS.md) äº†è§£é¡¹ç›®çº¦å®šã€‚

---

## ğŸ“„ è®¸å¯åè®®

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](./LICENSE)ã€‚åœ¨å¼•ç”¨æˆ–å†å‘å¸ƒæ¨¡å‹ä¸æ•°æ®æ—¶ï¼Œè¯·éµå®ˆç›¸åº”è®¸å¯è¯è¦æ±‚ã€‚
